#!/bin/bash

# Ø±ÙØ¹ Ù‚Ø·Ø¹ÛŒ Ù…Ø´Ú©Ù„ snscrape Ø¨Ø§ Ù¾Ø§ÛŒØªÙˆÙ† 3.12
echo "Ù†ØµØ¨ Ù†Ø³Ø®Ù‡ Ø³Ø§Ø²Ú¯Ø§Ø± snscrape Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØªÙˆÙ† 3.12..."
pip uninstall -y snscrape > /dev/null 2>&1
pip install git+https://github.com/JustAnotherArchivist/snscrape.git@master > /dev/null 2>&1

# Ø§ØµÙ„Ø§Ø­ predict.py Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ
echo "Ø§ØµÙ„Ø§Ø­ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ..."
cat > scripts/predict.py << 'EOF'
import os
import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# ØªÙ†Ø¸ÛŒÙ… Ù…Ø³ÛŒØ±Ù‡Ø§
DATA_DIR = os.path.join(os.path.dirname(__file__), '..', 'data')
MODEL_DIR = os.path.join(os.path.dirname(__file__), '..', 'models')
os.makedirs(MODEL_DIR, exist_ok=True)

def train_model():
    # Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    df = pd.read_csv(os.path.join(DATA_DIR, "dataset.csv"))
    
    # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    # ... (Ú©Ø¯Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ù…Ø§)
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    X = df.drop('target', axis=1)
    y = df['target']
    
    # Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ
    if len(X) < 2:
        print(f"âš ï¸  Ù‡Ø´Ø¯Ø§Ø±: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ (n_samples={len(X)}). Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø§ Ú©Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
        X_train, y_train = X, y
        
        # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø¯ÙˆÙ† ØªØ³Øª
        model = RandomForestClassifier(n_estimators=100)
        model.fit(X_train, y_train)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
        joblib.dump(model, os.path.join(MODEL_DIR, "viral_predict_model.pkl"))
        print("âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        return
    else:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    print("ðŸ—ï¸ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
    model = RandomForestClassifier(n_estimators=100)
    model.fit(X_train, y_train)
    
    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ðŸ“Š Ø¯Ù‚Øª Ù…Ø¯Ù„: {accuracy:.2f}")
    
    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§
    predictions = model.predict(X)
    df['prediction'] = predictions
    df.to_csv(os.path.join(DATA_DIR, "predictions.csv"), index=False)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
    joblib.dump(model, os.path.join(MODEL_DIR, "viral_predict_model.pkl"))
    print("âœ… Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

if __name__ == "__main__":
    train_model()
EOF

# Ø§ØµÙ„Ø§Ø­ generate_report.py Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ù…Ù„ Ø®Ø·Ø§Ù‡Ø§
echo "Ø§ØµÙ„Ø§Ø­ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ..."
cat > scripts/generate_report.py << 'EOF'
import os
import pandas as pd
from datetime import datetime

# ØªÙ†Ø¸ÛŒÙ… Ù…Ø³ÛŒØ±Ù‡Ø§
DATA_DIR = os.path.join(os.path.dirname(__file__), '..', 'data')
REPORT_DIR = os.path.join(os.path.dirname(__file__), '..', 'reports')
os.makedirs(REPORT_DIR, exist_ok=True)

def create_report():
    # Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§
    try:
        df = pd.read_csv(os.path.join(DATA_DIR, "predictions.csv"))
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        if df.empty:
            print("âš ï¸  Ù‡Ø´Ø¯Ø§Ø±: ÙØ§ÛŒÙ„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª")
            return
    except (FileNotFoundError, pd.errors.EmptyDataError) as e:
        print(f"âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: {e}")
        return
    
    # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
    print("ðŸ“ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ...")
    date_str = datetime.now().strftime("%Y-%m-%d_%H-%M")
    report_file = os.path.join(REPORT_DIR, f"viral_report_{date_str}.md")
    
    with open(report_file, 'w') as f:
        f.write("# Ú¯Ø²Ø§Ø±Ø´ Ù…Ø­ØªÙˆØ§Ù‡Ø§ÛŒ ÙˆÛŒØ±ÙˆØ³ÛŒ\n\n")
        f.write(f"ØªØ§Ø±ÛŒØ® ØªÙˆÙ„ÛŒØ¯: {datetime.now().strftime('%Y/%m/%d %H:%M')}\n\n")
        
        # 10 Ù…Ø­ØªÙˆØ§ÛŒ Ø¨Ø±ØªØ±
        top_content = df.sort_values('prediction', ascending=False).head(10)
        f.write("## 10 Ù…Ø­ØªÙˆØ§ÛŒ Ø¨Ø±ØªØ±\n\n")
        for i, row in top_content.iterrows():
            f.write(f"{i+1}. **{row['content'][:50]}...** - Ø§Ù…ØªÛŒØ§Ø² ÙˆÛŒØ±ÙˆØ³ÛŒ: {row['prediction']:.2f}\n")
    
    print(f"âœ… Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± {report_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

if __name__ == "__main__":
    create_report()
EOF

# Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù¾Ø§ÛŒÙ†â€ŒÙ„Ø§ÛŒÙ†
echo "Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§..."
python scripts/twitter_scraper.py

echo "Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ..."
python scripts/predict.py

echo "ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ..."
python scripts/generate_report.py

echo "âœ… ØªÙ…Ø§Ù… Ù…Ø±Ø§Ø­Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!"
