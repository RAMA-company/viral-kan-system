import os
import pandas as pd
import snscrape.modules.twitter as sntwitter
from datetime import datetime, timedelta
import random
import time
import sys

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
HASHTAGS = ["#crypto", "#bitcoin", "#ai", "#gaming", "#tech"]
MAX_TWEETS = 200
DATA_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'data')
os.makedirs(DATA_DIR, exist_ok=True)

def robust_scrape(query, max_tweets, retries=3):
    for attempt in range(retries):
        try:
            tweets = []
            scraper = sntwitter.TwitterSearchScraper(query)
            
            for i, tweet in enumerate(scraper.get_items()):
                if i >= max_tweets:
                    break
                
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± ÙˆØ§Ù‚Ø¹ÛŒ ØªÙˆÛŒÛŒØª
                tweet_data = [
                    tweet.date,
                    tweet.rawContent,
                    tweet.likeCount,
                    tweet.retweetCount,
                    tweet.replyCount,
                    query.split()[0]
                ]
                tweets.append(tweet_data)
            
            return tweets
            
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ (ØªÙ„Ø§Ø´ {attempt+1}/{retries}): {str(e)}")
            time.sleep(random.uniform(1, 3))
    
    print(f"âŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ {query} Ù¾Ø³ Ø§Ø² {retries} ØªÙ„Ø§Ø´ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
    return []

def scrape_twitter():
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªÙˆÛŒÛŒØªâ€ŒÙ‡Ø§...")
    end_date = datetime.now()
    start_date = end_date - timedelta(days=2)
    all_tweets = []
    
    print(f"ğŸ“Œ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {len(HASHTAGS)} Ù‡Ø´ØªÚ¯...")
    
    for hashtag in HASHTAGS:
        query = f"{hashtag} since:{start_date.date()} lang:en"
        print(f"ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ: {query}")
        
        tweets = robust_scrape(query, MAX_TWEETS)
        all_tweets.extend(tweets)
        print(f"âœ… {len(tweets)} ØªÙˆÛŒÛŒØª Ø¨Ø±Ø§ÛŒ {hashtag} Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯")
    
    if not all_tweets:
        print("âš ï¸ Ù‡ÛŒÚ† ØªÙˆÛŒÛŒØªÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†Ø´Ø¯! Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
        all_tweets = [
            [datetime.now(), "ØªÙˆÛŒÛŒØª Ù†Ù…ÙˆÙ†Ù‡: Ù¾ÛŒØ´Ø±ÙØªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ", 150, 25, 8, "#ai"],
            [datetime.now(), "ØªÙˆÛŒÛŒØª Ù†Ù…ÙˆÙ†Ù‡: ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†", 200, 40, 15, "#bitcoin"],
            [datetime.now(), "ØªÙˆÛŒÛŒØª Ù†Ù…ÙˆÙ†Ù‡: Ø¢Ø®Ø±ÛŒÙ† Ø§Ø®Ø¨Ø§Ø± Ø¨Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±ÛŒ", 180, 30, 10, "#gaming"],
            [datetime.now(), "ØªÙˆÛŒÛŒØª Ù†Ù…ÙˆÙ†Ù‡: ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ¸Ù‡ÙˆØ± Ø¯Ø± 2023", 120, 20, 6, "#tech"],
            [datetime.now(), "ØªÙˆÛŒÛŒØª Ù†Ù…ÙˆÙ†Ù‡: ØªØ­ÙˆÙ„Ø§Øª Ø¨Ø§Ø²Ø§Ø± Ø±Ù…Ø²Ø§Ø±Ø²Ù‡Ø§", 90, 15, 5, "#crypto"]
        ]
    
    # Ø§ÛŒØ¬Ø§Ø¯ DataFrame
    df = pd.DataFrame(all_tweets, 
                     columns=['datetime', 'content', 'likes', 'retweets', 'replies', 'hashtag'])
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø§Ù…Ù„ Ú©Ù„
    df['engagement'] = df['likes'] + (df['retweets'] * 2) + df['replies']
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡
    output_path = os.path.join(DATA_DIR, "dataset.csv")
    df.to_csv(output_path, index=False)
    print(f"ğŸ’¾ {len(df)} ØªÙˆÛŒÛŒØª Ø¯Ø± {output_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

if __name__ == "__main__":
    scrape_twitter()
